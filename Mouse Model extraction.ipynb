{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20963674-e574-4e28-817a-6d1e70ece4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "import ssl\n",
    "import pandas as pd\n",
    "from lxml import html\n",
    "from lxml.etree import tostring\n",
    "\n",
    "\n",
    "class CustomHttpAdapter (requests.adapters.HTTPAdapter):\n",
    "    # \"Transport adapter\" that allows us to use custom ssl_context.\n",
    "\n",
    "    def __init__(self, ssl_context=None, **kwargs):\n",
    "        self.ssl_context = ssl_context\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def init_poolmanager(self, connections, maxsize, block=False):\n",
    "        self.poolmanager = urllib3.poolmanager.PoolManager(\n",
    "            num_pools=connections, maxsize=maxsize,\n",
    "            block=block, ssl_context=self.ssl_context)\n",
    "\n",
    "\n",
    "def get_legacy_session():\n",
    "    ctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n",
    "    ctx.options |= 0x4  # OP_LEGACY_SERVER_CONNECT\n",
    "    session = requests.session()\n",
    "    session.mount('https://', CustomHttpAdapter(ctx))\n",
    "    return session\n",
    "\n",
    "def get_alliance_disease(code:str='DOID:9970',entity:str='models'):\n",
    "\n",
    "    url = f'https://www.alliancegenome.org/api/disease/DOID:0060643/models?page=1&limit=100000&sortBy='\n",
    "    \n",
    "    with(\n",
    "        get_legacy_session() as s,\n",
    "        s.get(url) as response\n",
    "    ):\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "        else:\n",
    "            data = None\n",
    "            \n",
    "    return data\n",
    "\n",
    "\n",
    "def filter_diseases(json_data):\n",
    "    \"\"\"\n",
    "    Filters the JSON data to only take entries with the category \"disease\"\n",
    "    \n",
    "    \"\"\"\n",
    "    filtered_data = []\n",
    "    for result in json_data['results']:\n",
    "        if result['category'] == 'disease':\n",
    "            filtered_data.append(result)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def get_disease_id(disease_name:str):\n",
    "    \n",
    "    url = f'https://www.alliancegenome.org/api/search_autocomplete?q={disease_name}'\n",
    "    with (\n",
    "        get_legacy_session() as s,\n",
    "        s.get(url) as response\n",
    "    ):\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            data = filter_diseases(data)\n",
    "            if len(data)>0:\n",
    "                data = data[0]['primaryKey']\n",
    "            else:\n",
    "                data = None\n",
    "        else:\n",
    "            data = None\n",
    "    #print(data)\n",
    "    #return {disease_name:data}\n",
    "    return data\n",
    "\n",
    "def get_multiple_diseases(disease_list,entity:str='models'):\n",
    "    \n",
    "    temp=[]\n",
    "    #print(disease_list)\n",
    "        \n",
    "    for disease in disease_list:\n",
    "        #print(disease)\n",
    "        data = get_alliance_disease(code=disease,entity=entity)\n",
    "     # print(data)\n",
    "        data = pd.json_normalize(\n",
    "        data, record_path=[\"results\"]\n",
    "        )\n",
    "        temp.append(data)\n",
    "        \n",
    "  #  print(temp)\n",
    "    results = pd.concat(temp, ignore_index=True)\n",
    "    \n",
    "    return results      \n",
    "      \n",
    "\n",
    "def get_multiple_diseases_from_name(disease_list,entity:str='models'):\n",
    "    \n",
    "    temp=[]\n",
    "   \n",
    "    for disease in disease_list:\n",
    "        data = get_disease_id(disease)\n",
    "        temp.append(data)\n",
    "       \n",
    "    #disease_data = get_multiple_diseases(temp)\n",
    "      \n",
    "    return data\n",
    "\n",
    "def get_multiple_diseases(disease_list,entity:str='models'):\n",
    "    \n",
    "    temp=[]\n",
    "    \n",
    "    for disease in disease_list:\n",
    "      #  print(disease)\n",
    "        data = get_alliance_disease(code=disease,entity=entity)\n",
    "       # print(data)\n",
    "        data = pd.json_normalize(\n",
    "        data, record_path=[\"results\"]\n",
    "        )\n",
    "        temp.append(data)\n",
    "        \n",
    "  #  print(temp)\n",
    "    results = pd.concat(temp, ignore_index=True)\n",
    "    \n",
    "    return results \n",
    "\n",
    "\n",
    "## MGI Phenotypes extraction\n",
    "\n",
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd\n",
    " \n",
    "def get_multiple_mouse_models(mouse_list):\n",
    "    \n",
    "    temp=[]\n",
    "    \n",
    "    for model in mouse_list:\n",
    "        model_id = model\n",
    "      #  data = parse_mice(model)    \n",
    "        page = requests.get(f'http://www.informatics.jax.org/allele/genoview/{model}')\n",
    "        tree = html.fromstring(page.content)\n",
    "        # Get ids using XPath\n",
    "        ids = tree.xpath('//div[@class=\"mpSystemRow\"]/@id')\n",
    "        text_ids = tree.xpath('//div[@class=\"mpSystemRow\"]/text()[normalize-space()]')\n",
    "        text_ids =[text.strip() for text in text_ids]\n",
    "        list_df = []\n",
    "        sex = []\n",
    "        # For each ids get content\n",
    "        for id, text in zip(ids, text_ids):\n",
    "            data = {}\n",
    "            subtext = tree.xpath(f'(//div[contains(@id, \"{id}\") and @class=\"termDiv\"]//text()[normalize-space()])')\n",
    "            divs = tree.xpath(f'//div[contains(@id, \"{id}\") and @class=\"termDiv\"]')\n",
    "            for div in divs:\n",
    "                img = div.xpath('.//img[contains(@class, \"mp_glyph\")]/@src')\n",
    "                if len(img) >0:\n",
    "                    if \"Mars\" in img[0]:\n",
    "                        sex.append(\"Male\")\n",
    "                    else:\n",
    "                        sex.append(\"Female\")\n",
    "                else:\n",
    "                    sex.append(\"Neutral\")\n",
    "            cleaned = [text.strip() for text in subtext]\n",
    "            indices = [i for i, s in enumerate(cleaned) if 'J:' in s]\n",
    "            features = [cleaned[i-2] for i in indices]\n",
    "            feautres_jterms = [cleaned[i] for i in indices]\n",
    "            texts = [cleaned[indices[i]+2:indices[i+1]-2] for i in range(len(indices)-1)]\n",
    "            texts.extend([cleaned[indices[-1]+2:]])\n",
    "            system = [text for i in range(len(texts))]\n",
    "            request_ids = [model for i in range(len(texts))]\n",
    "            data['model']=model_id\n",
    "            data['system'] = system\n",
    "            data['features_jterms'] = feautres_jterms\n",
    "            data['features'] = features\n",
    "            data['comments'] = texts\n",
    "            #data['sex'] = sex\n",
    "            list_df.append(pd.DataFrame(data))\n",
    "        df = pd.concat(list_df, ignore_index=True)\n",
    "        \n",
    "        temp.append(df)\n",
    "        \n",
    "  \n",
    "    results = pd.concat(temp, ignore_index=True)\n",
    "    \n",
    "    return results \n",
    "\n",
    "def parse_first_table(request_id='MGI:6719082'):\n",
    "    page = requests.get(f'http://www.informatics.jax.org/allele/genoview/{request_id}')\n",
    "    tree = html.fromstring(page.content) \n",
    "    table = tree.xpath('//*[@id=\"templateBodyInsert\"]/div[2]/div/div[2]/table')[0]\n",
    "    table = pd.concat(pd.read_html(html.etree.tostring(table)))\n",
    "    table = table.reset_index(drop=True)\n",
    "    table = table[1:].T\n",
    "    table.columns = table.iloc[0] \n",
    "    table = table[1:].dropna()\n",
    "    table['Allelic Composition'] = table['Allelic Composition'].apply(lambda x: x.split(' '))\n",
    "    table['Genetic Background'] = table['Genetic Background'].apply(lambda x: x.replace('involves:', '').split('*'))\n",
    "    table['Find Mice'] = table['Find Mice'].apply(lambda x: x.split('Mouse lines carrying:')[1].split(';'))\n",
    "    return table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explorare",
   "language": "python",
   "name": "explorare"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
